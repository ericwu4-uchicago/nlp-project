{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there exist 85 federalist papers\n",
    "#18-20, 49-58, and 64 have debated authors\n",
    "#the authors are hamilton(1), jay(2), and madison(3)\n",
    "#in order to prevent fitting on number/author in title all that info is thrown into first line which is filtered\n",
    "#sources:\n",
    "#https://www.drjosephliu.com/posts/how-to-apply-end-to-end-ensembling-with-bert-for-author-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8478c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: torch==1.11 in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: torchdata in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: torchtext in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from torch==1.11) (4.5.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from torchdata) (1.26.15)\n",
      "Requirement already satisfied: requests in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from torchdata) (2.29.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from torchtext) (1.23.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from torchtext) (4.65.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from requests->torchdata) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from requests->torchdata) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from requests->torchdata) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
      "Requirement already satisfied: sacrebleu in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: portalocker in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from sacrebleu) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from sacrebleu) (1.23.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from sacrebleu) (4.9.2)\n",
      "Requirement already satisfied: regex in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from sacrebleu) (2022.7.9)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from sacrebleu) (0.8.10)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\ewu15\\anaconda3\\lib\\site-packages (from portalocker->sacrebleu) (305.1)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.11 torchdata torchtext\n",
    "!pip install sacrebleu\n",
    "!pip install evaluate\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22fafa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download('popular')\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup, \n",
    "    XLMRobertaForSequenceClassification,\n",
    "    AutoTokenizer, AutoModelForMaskedLM\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "from array import array\n",
    "#import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9fcf88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "#model = XLMRobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\") #, problem_type=\"multi_label_classification\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1484558",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1250093",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m predicted_class_ids \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#model.config.id2label\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid2label\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredicted_class_ids\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1250093"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "predicted_class_ids = logits.argmax().item()\n",
    "#model.config.id2label\n",
    "model.config.id2label[predicted_class_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07906087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "codes = np.array([1,2,2,2,2,1,1,1,1,3,1,1,1,3,1,1,1,3,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,\n",
    "        1,1,1,3,3,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\n",
    "known = [True] * 85\n",
    "known[63] = False\n",
    "known[17:20] = [False] * 3\n",
    "known[48:58] = [False] * 10\n",
    "print(len(known))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbbd9cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_type = 'bert'\n",
    "model_name = 'bert-base-cased'\n",
    "config_class, model_class, tokenizer_class = BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "config = config_class.from_pretrained(model_name, num_labels=50)\n",
    "model = model_class.from_pretrained(model_name, config=config)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "#tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437d394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    texts = []\n",
    "    textprepath = \"Federalist Papers/fed paper \"\n",
    "    texts = []\n",
    "    for i in range(85):\n",
    "        f = open(f\"{textprepath}{i + 1}.txt\", \"r\")\n",
    "        text = f.read()\n",
    "        parts = text.split(\"\\n\", 1) #split out the first line\n",
    "        f.close()\n",
    "        texts.append({'text':parts[1]})\n",
    "    df = pd.DataFrame(texts)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ae4314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#authors are tolstoy, beliaev, teffi, danilevskii, averchenko, chiornyi\n",
    "#authors = np.repeat([1, 2, 2, 3, 4, 5, 4, 5, 6], 3)\n",
    "authors = np.repeat([1, 3, 2, 2, 3, 3, 2, 2, 3, 5, 4, 5, 3, 5, 2, 5, 6, 3, 5], 3)\n",
    "#huggingface, google, deepl\n",
    "translators = np.repeat([1, 2, 3],19)\n",
    "fullds =[] \n",
    "directory = \"russian short stories\"\n",
    "directories = ['init translations', 'google translation', 'deepl translations']\n",
    "#directory = \"test translation\"\n",
    "#files = [\"Сказка о лысом пророке Елисее chiornyi.txt\"]\n",
    "for directory in directories:\n",
    "    #print(directory)\n",
    "    for file in os.listdir(directory):\n",
    "#for file in files:\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".txt\"):\n",
    "            #print(filename)\n",
    "            #f = open(f\"{directory}/{filename}\", encoding='utf-8') #'r',\n",
    "            f = open(f\"{directory}/{filename}\", 'r',encoding='utf-8')\n",
    "            text = f.read()\n",
    "            f.close()\n",
    "            fullds.append({'text':text})\n",
    "            #fullds.append(text)\n",
    "translated_df = pd.DataFrame(fullds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49a38ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "train = known and [i % 8 != 0 for i in range(len(known))]\n",
    "test = known and [i % 8 == 0 for i in range(len(known))]\n",
    "train_df = data[train]\n",
    "test_df = data[test]\n",
    "codestrain = codes[train]\n",
    "codestest = codes[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfd74d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intrain = [i % 5 != 0 for i in range(translated_df.size)]\n",
    "intrain = [i % 9 > 2 for i in range(translated_df.size)]\n",
    "#intrain = [True, True, True, True, True, True, False, False, False,\n",
    "#          True, True, True, False, False, False, True, True, True, \n",
    "#          False, False, False, True, True, True, True, True, True,]\n",
    "#notintrain = [i % 9 <= 2 for i in range(translated_df.size)]\n",
    "notintrain = [not element for element in intrain]\n",
    "train_df = translated_df[intrain]\n",
    "test_df = translated_df[notintrain]\n",
    "#codestrain = authors[intrain]\n",
    "codestrain = translators[intrain]\n",
    "#codestest = authors[notintrain]\n",
    "codestest = translators[notintrain]\n",
    "#print(train_df)\n",
    "#print(codestrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6eee977",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512 #arb chosen. may be subject to change\n",
    "#MAX_LEN = 128\n",
    "def get_encodings(texts):\n",
    "    token_ids = []\n",
    "    for text in texts:\n",
    "        token_id = tokenizer.encode(text, \n",
    "                                    add_special_tokens=True,\n",
    "                                    truncation=True,\n",
    "                                    max_length=MAX_LEN,\n",
    "                                    padding='max_length')\n",
    "                                    #pad_to_max_length=True)\n",
    "        token_ids.append(token_id)\n",
    "    return token_ids\n",
    "\n",
    "def get_attention_masks(padded_encodings):\n",
    "    attention_masks = []\n",
    "    for encoding in padded_encodings:\n",
    "        attention_mask = [int(token_id > 0) for token_id in encoding]\n",
    "        attention_masks.append(attention_mask)\n",
    "    return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1495dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = get_encodings(train_df.text.values)\n",
    "train_attention_masks = get_attention_masks(train_encodings)\n",
    "\n",
    "test_encodings = get_encodings(test_df.text.values)\n",
    "test_attention_masks = get_attention_masks(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ac6ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "#batch_size = 1\n",
    "# Load input data into tensors\n",
    "train_input_ids = torch.tensor(train_encodings)\n",
    "train_masks = torch.tensor(train_attention_masks)\n",
    "train_labels = torch.tensor(codestrain)\n",
    "\n",
    "test_input_ids = torch.tensor(test_encodings)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "test_labels = torch.tensor(codestest)\n",
    "\n",
    "# Create the DataLoader and Sampler for both sets.\n",
    "train_data = TensorDataset(train_input_ids, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_input_ids, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "554df95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lr = 4e-5\n",
    "eps = 1e-8\n",
    "epochs = 5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70d41282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9492615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 11 ========\n",
      "\n",
      "  Accuracy: 0.111\n",
      "  Average training loss: 3.573\n",
      "  Accuracy: 0.292\n",
      "  Average eval loss: 2.717\n",
      "\n",
      "======== Epoch 2 / 11 ========\n",
      "\n",
      "  Accuracy: 0.222\n",
      "  Average training loss: 2.353\n",
      "  Accuracy: 0.333\n",
      "  Average eval loss: 1.790\n",
      "\n",
      "======== Epoch 3 / 11 ========\n",
      "\n",
      "  Accuracy: 0.583\n",
      "  Average training loss: 1.599\n",
      "  Accuracy: 0.375\n",
      "  Average eval loss: 1.467\n",
      "\n",
      "======== Epoch 4 / 11 ========\n",
      "\n",
      "  Accuracy: 0.583\n",
      "  Average training loss: 1.353\n",
      "  Accuracy: 0.292\n",
      "  Average eval loss: 1.365\n",
      "\n",
      "======== Epoch 5 / 11 ========\n",
      "\n",
      "  Accuracy: 0.583\n",
      "  Average training loss: 1.228\n",
      "  Accuracy: 0.333\n",
      "  Average eval loss: 1.433\n",
      "\n",
      "======== Epoch 6 / 11 ========\n",
      "\n",
      "  Accuracy: 0.444\n",
      "  Average training loss: 1.100\n",
      "  Accuracy: 0.417\n",
      "  Average eval loss: 1.143\n",
      "\n",
      "======== Epoch 7 / 11 ========\n",
      "\n",
      "  Accuracy: 0.722\n",
      "  Average training loss: 0.846\n",
      "  Accuracy: 0.417\n",
      "  Average eval loss: 1.124\n",
      "\n",
      "======== Epoch 8 / 11 ========\n",
      "\n",
      "  Accuracy: 0.861\n",
      "  Average training loss: 0.637\n",
      "  Accuracy: 0.542\n",
      "  Average eval loss: 0.839\n",
      "\n",
      "======== Epoch 9 / 11 ========\n",
      "\n",
      "  Accuracy: 0.972\n",
      "  Average training loss: 0.437\n",
      "  Accuracy: 0.875\n",
      "  Average eval loss: 0.552\n",
      "\n",
      "======== Epoch 10 / 11 ========\n",
      "\n",
      "  Accuracy: 1.000\n",
      "  Average training loss: 0.226\n",
      "  Accuracy: 0.917\n",
      "  Average eval loss: 0.416\n",
      "\n",
      "======== Epoch 11 / 11 ========\n",
      "\n",
      "  Accuracy: 1.000\n",
      "  Average training loss: 0.130\n",
      "  Accuracy: 0.750\n",
      "  Average eval loss: 0.651\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "#              Training 6 11\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epochs = 11\n",
    "for epoch_i in range(0, epochs):\n",
    "    print('\\n======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "        input_ids, input_masks, labels = tuple(t for t in batch)# .to(device)\n",
    "        model.zero_grad()     \n",
    "        #print(input_ids.shape)\n",
    "        #print(labels.shape)\n",
    "        #outputs = model(torch.LongTensor(input_ids), attention_mask=torch.LongTensor(input_masks), labels=labels) #complains here\n",
    "        outputs = model(input_ids.to(torch.long), attention_mask=input_masks.to(torch.long), labels=labels.to(torch.long))\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        batch_accuracy = flat_accuracy(logits, labels)\n",
    "        # Accumulate the total accuracy.\n",
    "        train_accuracy += batch_accuracy\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)   \n",
    "    avg_train_accuracy = train_accuracy / len(train_dataloader)        \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    train_loss_values.append(avg_train_loss)\n",
    "    print(\"\\n  Accuracy: {0:.3f}\".format(avg_train_accuracy))\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    #print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "    #  Test\n",
    "    # After the completion of each training epoch, measure our performance on our test set.\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    test_loss, test_accuracy = 0, 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        input_ids, input_masks, labels = tuple(t for t in batch) #.to(device)\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(input_ids.to(torch.long), attention_mask=input_masks.to(torch.long), labels=labels.to(torch.long))\n",
    "            #outputs = model(input_ids, attention_mask=input_masks,labels=labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        labels = labels.to('cpu').numpy()\n",
    "\n",
    "        batch_accuracy = flat_accuracy(logits, labels)\n",
    "        test_accuracy += batch_accuracy\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    avg_test_accuracy = test_accuracy / len(test_dataloader)\n",
    "\n",
    "    test_loss_values.append(avg_test_loss)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.3f}\".format(avg_test_accuracy))\n",
    "    print(\"  Average eval loss: {0:.3f}\".format(avg_test_loss))\n",
    "    #print(\"  Testing took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7095f3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [1 1 1 1]\n",
      "labels: [1 1 1 1]\n",
      "predictions: [1 3 1 2]\n",
      "labels: [1 1 1 2]\n",
      "predictions: [2 2 3 2]\n",
      "labels: [2 2 2 2]\n",
      "predictions: [2 2 3 3]\n",
      "labels: [2 2 3 3]\n",
      "predictions: [3 3 3 3]\n",
      "labels: [3 3 3 3]\n",
      "predictions: [1]\n",
      "labels: [3]\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "labels_true = []\n",
    "labels_pred = []\n",
    "for batch in test_dataloader:\n",
    "    input_ids, input_masks, labels = tuple(t for t in batch)\n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids.to(torch.long), attention_mask=input_masks.to(torch.long), labels=labels.to(torch.long))\n",
    "        logits = outputs[1]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        labels = labels.to('cpu').numpy()\n",
    "        pred_flat = np.argmax((logits), axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "        #https://stackoverflow.com/questions/40336601/python-appending-array-to-an-array\n",
    "        for element in pred_flat:\n",
    "            labels_pred.append(element)\n",
    "        for element in labels_flat:\n",
    "            labels_true.append(element)\n",
    "        #labels_pred += np.append(labels_pred, pred_flat)\n",
    "        #labels_true += np.append(labels_true, labels_flat)\n",
    "        print(f\"predictions: {pred_flat}\")\n",
    "        print(f\"labels: {labels_flat}\")\n",
    "    \n",
    "f = f1_score(labels_true, labels_pred, average='micro')\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d0d4e5",
   "metadata": {},
   "source": [
    "for 20 epochs exhibits overfitting:\n",
    "predictions: 3 3 1 3 3 2 1 3 3 1 2 2 2 2 3 2 2 2 3 2 3\n",
    "labels     : 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n",
    "1: 2/7 2: 4/7 3: 3/7\n",
    "for 8 epochs lowest loss:\n",
    "predictions: 1 3 1 2 3 1 1 3 3 1 2 3 1 3 3 1 1 2 1 1 3\n",
    "labels     : 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n",
    "1: 4/7 2: 1/7 3: 2/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fece5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def punctuation_removal(x):\n",
    "    temp = \"\"\n",
    "    for i in x:\n",
    "        if i not in string.punctuation:\n",
    "            temp+=i\n",
    "    return temp\n",
    "\n",
    "def lemmatize(x):\n",
    "    temp = \"\"\n",
    "    for i in range(len(x.split())):\n",
    "        lem = lemmatizer.lemmatize(x.split()[i], pos=\"v\")\n",
    "        temp += lem + \" \"\n",
    "    temp = temp.rstrip()\n",
    "    return temp\n",
    "\n",
    "def stopword_removal(x):\n",
    "    temp = \"\"\n",
    "    for i in x.split():\n",
    "        if i.lower() not in stopwords.words('english'):\n",
    "            temp += i + \" \"\n",
    "    temp = temp.rstrip()\n",
    "    return temp\n",
    "\n",
    "def text_processing(X_train):\n",
    "    processed_text = []\n",
    "    #for i in X_train:\n",
    "    temp = punctuation_removal(X_train)\n",
    "    temp = lemmatize(temp)\n",
    "    temp = stopword_removal(temp)\n",
    "    processed_text.append(temp)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b41032af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create BoW\n",
    "#bow_transformer = CountVectorizer(analyzer=text_processing).fit(train_df.text.values)\n",
    "#text_bow_train = bow_transformer.transform(train_df.text.values)\n",
    "#text_bow_test = bow_transformer.transform(test_df.text.values)\n",
    "\n",
    "# # Save BoW\n",
    "# pickle.dump(text_bow_train, open(DATA_PATH + \"text_bow_train.p\", \"wb\"))\n",
    "# pickle.dump(text_bow_test, open(DATA_PATH + \"text_bow_test.p\", \"wb\"))\n",
    "DATA_PATH = \"\"\n",
    "# Load pre-made BoW\n",
    "text_bow_train = pickle.load(open(DATA_PATH + \"text_bow_train.p\", \"rb\"))\n",
    "text_bow_test = pickle.load(open(DATA_PATH + \"text_bow_test.p\", \"rb\"))\n",
    "\n",
    "train_bow = torch.tensor(text_bow_train.todense(), dtype = torch.double)\n",
    "test_bow = torch.tensor(text_bow_test.todense(), dtype = torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e588341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = \"C:/Users\\ewu15\\Documents\\NLP\"\n",
    "DATA_PATH = \"\"\n",
    "pickle.dump(text_bow_train, open(DATA_PATH + \"text_bow_train.p\", \"wb\"))\n",
    "pickle.dump(text_bow_test, open(DATA_PATH + \"text_bow_test.p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60b15f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow = torch.tensor(text_bow_train.todense(), dtype = torch.double)\n",
    "test_bow = torch.tensor(text_bow_test.todense(), dtype = torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3422db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids, train_masks, train_bow, train_labels)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids, test_masks, test_bow, test_labels)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)\n",
    "# Parameters\n",
    "lr = 1e-4\n",
    "eps = 1e-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56048de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use log reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b1cf8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \"\"\"\n",
    "    End to end neural net that combines with BERT model\n",
    "    \"\"\"\n",
    "    def __init__(self, bert_model):\n",
    "        super().__init__()\n",
    "        #self.hidden1 = nn.Linear(815, 700)\n",
    "        #self.hidden1 = nn.Linear(853, 700)\n",
    "        self.hidden1 = nn.Linear(804, 700)\n",
    "        #self.hidden1 = nn.Linear(786, 512)\n",
    "        self.output = nn.Linear(700, 50)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(700)\n",
    "        self.bert = bert_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        \n",
    "        #print(type(x))\n",
    "        x = self.hidden1(x)\n",
    "        #x = self.bert(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa5c50e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(model_name, num_labels=50, output_hidden_states=True)\n",
    "bert = model_class.from_pretrained(model_name, config=config)\n",
    "#bert.to(device)\n",
    "\n",
    "nnet = NeuralNet(bert)\n",
    "#nnet.double().to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.AdamW(nnet.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca8bd065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Accuracy: 0.900\n",
      "  Average training loss: 0.508\n",
      "Running Testing...\n",
      "  Accuracy: 0.167\n",
      "  Average eval loss: 2.422\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Accuracy: 0.950\n",
      "  Average training loss: 0.397\n",
      "Running Testing...\n",
      "  Accuracy: 0.167\n",
      "  Average eval loss: 2.399\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Accuracy: 0.975\n",
      "  Average training loss: 0.414\n",
      "Running Testing...\n",
      "  Accuracy: 0.167\n",
      "  Average eval loss: 2.398\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Accuracy: 1.000\n",
      "  Average training loss: 0.353\n",
      "Running Testing...\n",
      "  Accuracy: 0.167\n",
      "  Average eval loss: 2.397\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Accuracy: 0.950\n",
      "  Average training loss: 0.355\n",
      "Running Testing...\n",
      "  Accuracy: 0.125\n",
      "  Average eval loss: 2.402\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Run input IDs and masks through BERT first to get embeddings\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# then combine with BOW to run through rest of nnet model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# output[1] are the hidden states.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1552\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1552\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1566\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1005\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1007\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1008\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1009\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1027\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:603\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    594\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    595\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    596\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 603\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:531\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    528\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    529\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 531\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pytorch_utils.py:246\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:543\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 543\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:443\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 443\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#               Training\n",
    "# ========================================\n",
    "lr = 5e-4\n",
    "epochs = int(50 / 5)\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    nnet.train()\n",
    "    t0 = time.time()\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        input_ids, input_masks, bow, labels = tuple(t for t in batch) #.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Run input IDs and masks through BERT first to get embeddings\n",
    "        # then combine with BOW to run through rest of nnet model\n",
    "        output = nnet.bert(input_ids, attention_mask=input_masks)\n",
    "\n",
    "        # output[1] are the hidden states.\n",
    "        embeddings = output[1][0]\n",
    "        embeddings = embeddings.mean(dim=1).double() \n",
    "\n",
    "        features_comb = torch.cat((embeddings, bow), dim=1)\n",
    "\n",
    "        outputs = nnet(features_comb)\n",
    "        vals, inds = torch.max(outputs, dim=1)\n",
    "        labels = labels.long()\n",
    "        loss = loss_function(outputs, labels)\n",
    "        train_loss += loss\n",
    "\n",
    "        batch_accuracy = torch.eq(inds, labels).sum().item() / labels.shape[0]\n",
    "        train_accuracy += batch_accuracy\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    avg_train_accuracy = train_accuracy / len(train_dataloader)\n",
    "    train_loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"  Accuracy: {0:.3f}\".format(avg_train_accuracy))\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    #print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #                   Test\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"Running Testing...\")\n",
    "\n",
    "    nnet.eval()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    test_loss, test_accuracy = 0, 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, input_masks, bow, labels = tuple(t for t in batch) #.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = nnet.bert(input_ids, attention_mask=input_masks)\n",
    "            embeddings = output[1][0]\n",
    "            embeddings = embeddings.mean(dim=1).double() \n",
    "\n",
    "            features_comb = torch.cat((embeddings, bow), dim=1)\n",
    "\n",
    "            outputs = nnet(features_comb)\n",
    "            vals, inds = torch.max(outputs, dim=1)\n",
    "            labels = labels.long()\n",
    "            loss = loss_function(outputs, labels)\n",
    "            test_loss += loss\n",
    "\n",
    "            batch_accuracy = torch.eq(inds, labels).sum().item() / labels.shape[0]\n",
    "            test_accuracy += batch_accuracy\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    avg_test_accuracy = test_accuracy / len(test_dataloader)\n",
    "    test_loss_values.append(avg_test_loss)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.3f}\".format(avg_test_accuracy))\n",
    "    print(\"  Average eval loss: {0:.3f}\".format(avg_test_loss))\n",
    "    #print(\"  Testing took: {:}\".format(format_time(time.time() - t0)))\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for batch in test_dataloader:\n",
    "    input_ids, input_masks, bow, labels = tuple(t for t in batch)#.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = nnet.bert(input_ids, attention_mask=input_masks)\n",
    "        embeddings = output[1][0]\n",
    "        embeddings = embeddings.mean(dim=1).double() \n",
    "        features_comb = torch.cat((embeddings, bow), dim=1)\n",
    "        outputs = nnet(features_comb)\n",
    "        vals, inds = torch.max(outputs, dim=1)\n",
    "        labels = labels.long()\n",
    "        #print(outputs)\n",
    "        print(inds)\n",
    "        print(labels)\n",
    "        batch_accuracy = torch.eq(inds, labels).sum().item() / labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37825f55",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#ensor.detach().numpy()\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_loss_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m())\n\u001b[0;32m      7\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(x, train_loss_values\u001b[38;5;241m.\u001b[39mnumpy(), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'value'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcu0lEQVR4nO3db2yV5f348U9paaturRG0FkEEpxMl6mgDo6wandag0ZBskcVF1GliszmETqeMRYYxaXTRfXUKbgoaE3REReeDztEHG1Zxf2DFGCFxEWZBW0kxtqhbGXD/Hhj6W9fiOLV/uNrXK7kfnMv7Puc6uazn7X2fP3lZlmUBAJCAMcM9AQCAIyVcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGTkHC6vvPJKXHnllTFhwoTIy8uLF1988X8es2HDhqioqIji4uKYOnVqPProo/2ZKwAwyuUcLp988kmcd9558fDDDx/R/jt27IjLL788qquro7m5OX7yk5/EwoUL4/nnn895sgDA6Jb3RX5kMS8vL1544YWYN2/eYfe544474qWXXopt27Z1j9XW1sYbb7wRr7/+en8fGgAYhQoG+wFef/31qKmp6TF22WWXxapVq+Lf//53jB07ttcxXV1d0dXV1X374MGD8eGHH8a4ceMiLy9vsKcMAAyALMti7969MWHChBgzZmDeVjvo4dLW1hZlZWU9xsrKymL//v3R3t4e5eXlvY6pr6+P5cuXD/bUAIAhsHPnzpg4ceKA3Negh0tE9DpLcujq1OHOnixZsiTq6uq6b3d0dMSpp54aO3fujJKSksGbKAAwYDo7O2PSpEnx5S9/ecDuc9DD5eSTT462trYeY7t3746CgoIYN25cn8cUFRVFUVFRr/GSkhLhAgCJGci3eQz697jMnj07Ghsbe4ytX78+Kisr+3x/CwDA4eQcLh9//HFs2bIltmzZEhGffdx5y5Yt0dLSEhGfXeZZsGBB9/61tbXx7rvvRl1dXWzbti1Wr14dq1atittuu21gngEAMGrkfKlo06ZNcdFFF3XfPvRelOuuuy6efPLJaG1t7Y6YiIgpU6ZEQ0NDLF68OB555JGYMGFCPPTQQ/Gtb31rAKYPAIwmX+h7XIZKZ2dnlJaWRkdHh/e4AEAiBuP1228VAQDJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQjH6Fy4oVK2LKlClRXFwcFRUV0dTU9Ln7r1mzJs4777w49thjo7y8PG644YbYs2dPvyYMAIxeOYfL2rVrY9GiRbF06dJobm6O6urqmDt3brS0tPS5/6uvvhoLFiyIG2+8Md5666149tln469//WvcdNNNX3jyAMDoknO4PPDAA3HjjTfGTTfdFNOmTYv/+7//i0mTJsXKlSv73P9Pf/pTnHbaabFw4cKYMmVKfOMb34ibb745Nm3a9IUnDwCMLjmFy759+2Lz5s1RU1PTY7ympiY2btzY5zFVVVWxa9euaGhoiCzL4oMPPojnnnsurrjiisM+TldXV3R2dvbYAAByCpf29vY4cOBAlJWV9RgvKyuLtra2Po+pqqqKNWvWxPz586OwsDBOPvnkOP744+OXv/zlYR+nvr4+SktLu7dJkyblMk0AYITq15tz8/LyetzOsqzX2CFbt26NhQsXxl133RWbN2+Ol19+OXbs2BG1tbWHvf8lS5ZER0dH97Zz587+TBMAGGEKctl5/PjxkZ+f3+vsyu7du3udhTmkvr4+5syZE7fffntERJx77rlx3HHHRXV1ddxzzz1RXl7e65iioqIoKirKZWoAwCiQ0xmXwsLCqKioiMbGxh7jjY2NUVVV1ecxn376aYwZ0/Nh8vPzI+KzMzUAAEcq50tFdXV18fjjj8fq1atj27ZtsXjx4mhpaem+9LNkyZJYsGBB9/5XXnllrFu3LlauXBnbt2+P1157LRYuXBgzZ86MCRMmDNwzAQBGvJwuFUVEzJ8/P/bs2RN33313tLa2xvTp06OhoSEmT54cERGtra09vtPl+uuvj71798bDDz8cP/rRj+L444+Piy++OO69996BexYAwKiQlyVwvaazszNKS0ujo6MjSkpKhns6AMARGIzXb79VBAAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMvoVLitWrIgpU6ZEcXFxVFRURFNT0+fu39XVFUuXLo3JkydHUVFRnH766bF69ep+TRgAGL0Kcj1g7dq1sWjRolixYkXMmTMnfvWrX8XcuXNj69atceqpp/Z5zNVXXx0ffPBBrFq1Kr7yla/E7t27Y//+/V948gDA6JKXZVmWywGzZs2KGTNmxMqVK7vHpk2bFvPmzYv6+vpe+7/88svxne98J7Zv3x4nnHBCvybZ2dkZpaWl0dHRESUlJf26DwBgaA3G63dOl4r27dsXmzdvjpqamh7jNTU1sXHjxj6Peemll6KysjLuu+++OOWUU+LMM8+M2267Lf75z38e9nG6urqis7OzxwYAkNOlovb29jhw4ECUlZX1GC8rK4u2trY+j9m+fXu8+uqrUVxcHC+88EK0t7fH97///fjwww8P+z6X+vr6WL58eS5TAwBGgX69OTcvL6/H7SzLeo0dcvDgwcjLy4s1a9bEzJkz4/LLL48HHnggnnzyycOedVmyZEl0dHR0bzt37uzPNAGAESanMy7jx4+P/Pz8XmdXdu/e3esszCHl5eVxyimnRGlpaffYtGnTIsuy2LVrV5xxxhm9jikqKoqioqJcpgYAjAI5nXEpLCyMioqKaGxs7DHe2NgYVVVVfR4zZ86ceP/99+Pjjz/uHnv77bdjzJgxMXHixH5MGQAYrXK+VFRXVxePP/54rF69OrZt2xaLFy+OlpaWqK2tjYjPLvMsWLCge/9rrrkmxo0bFzfccENs3bo1Xnnllbj99tvje9/7XhxzzDED90wAgBEv5+9xmT9/fuzZsyfuvvvuaG1tjenTp0dDQ0NMnjw5IiJaW1ujpaWle/8vfelL0djYGD/84Q+jsrIyxo0bF1dffXXcc889A/csAIBRIefvcRkOvscFANIz7N/jAgAwnIQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJKNf4bJixYqYMmVKFBcXR0VFRTQ1NR3Rca+99loUFBTE+eef35+HBQBGuZzDZe3atbFo0aJYunRpNDc3R3V1dcydOzdaWlo+97iOjo5YsGBBfPOb3+z3ZAGA0S0vy7IslwNmzZoVM2bMiJUrV3aPTZs2LebNmxf19fWHPe473/lOnHHGGZGfnx8vvvhibNmy5bD7dnV1RVdXV/ftzs7OmDRpUnR0dERJSUku0wUAhklnZ2eUlpYO6Ot3Tmdc9u3bF5s3b46ampoe4zU1NbFx48bDHvfEE0/EO++8E8uWLTuix6mvr4/S0tLubdKkSblMEwAYoXIKl/b29jhw4ECUlZX1GC8rK4u2trY+j/n73/8ed955Z6xZsyYKCgqO6HGWLFkSHR0d3dvOnTtzmSYAMEIdWUn8l7y8vB63syzrNRYRceDAgbjmmmti+fLlceaZZx7x/RcVFUVRUVF/pgYAjGA5hcv48eMjPz+/19mV3bt39zoLExGxd+/e2LRpUzQ3N8ctt9wSEREHDx6MLMuioKAg1q9fHxdffPEXmD4AMJrkdKmosLAwKioqorGxscd4Y2NjVFVV9dq/pKQk3nzzzdiyZUv3VltbG1/96ldjy5YtMWvWrC82ewBgVMn5UlFdXV1ce+21UVlZGbNnz45f//rX0dLSErW1tRHx2ftT3nvvvXjqqadizJgxMX369B7Hn3TSSVFcXNxrHADgf8k5XObPnx979uyJu+++O1pbW2P69OnR0NAQkydPjoiI1tbW//mdLgAA/ZHz97gMh8H4HDgAMLiG/XtcAACGk3ABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZPQrXFasWBFTpkyJ4uLiqKioiKampsPuu27durj00kvjxBNPjJKSkpg9e3b8/ve/7/eEAYDRK+dwWbt2bSxatCiWLl0azc3NUV1dHXPnzo2WlpY+93/llVfi0ksvjYaGhti8eXNcdNFFceWVV0Zzc/MXnjwAMLrkZVmW5XLArFmzYsaMGbFy5crusWnTpsW8efOivr7+iO7jnHPOifnz58ddd93V5z/v6uqKrq6u7tudnZ0xadKk6OjoiJKSklymCwAMk87OzigtLR3Q1++czrjs27cvNm/eHDU1NT3Ga2pqYuPGjUd0HwcPHoy9e/fGCSeccNh96uvro7S0tHubNGlSLtMEAEaonMKlvb09Dhw4EGVlZT3Gy8rKoq2t7Yju4/77749PPvkkrr766sPus2TJkujo6Ojedu7cmcs0AYARqqA/B+Xl5fW4nWVZr7G+PPPMM/Gzn/0sfvvb38ZJJ5102P2KioqiqKioP1MDAEawnMJl/PjxkZ+f3+vsyu7du3udhflva9eujRtvvDGeffbZuOSSS3KfKQAw6uV0qaiwsDAqKiqisbGxx3hjY2NUVVUd9rhnnnkmrr/++nj66afjiiuu6N9MAYBRL+dLRXV1dXHttddGZWVlzJ49O379619HS0tL1NbWRsRn709577334qmnnoqIz6JlwYIF8eCDD8bXv/717rM1xxxzTJSWlg7gUwEARrqcw2X+/PmxZ8+euPvuu6O1tTWmT58eDQ0NMXny5IiIaG1t7fGdLr/61a9i//798YMf/CB+8IMfdI9fd9118eSTT37xZwAAjBo5f4/LcBiMz4EDAINr2L/HBQBgOAkXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASEa/wmXFihUxZcqUKC4ujoqKimhqavrc/Tds2BAVFRVRXFwcU6dOjUcffbRfkwUARrecw2Xt2rWxaNGiWLp0aTQ3N0d1dXXMnTs3Wlpa+tx/x44dcfnll0d1dXU0NzfHT37yk1i4cGE8//zzX3jyAMDokpdlWZbLAbNmzYoZM2bEypUru8emTZsW8+bNi/r6+l7733HHHfHSSy/Ftm3busdqa2vjjTfeiNdff73Px+jq6oqurq7u2x0dHXHqqafGzp07o6SkJJfpAgDDpLOzMyZNmhQfffRRlJaWDsydZjno6urK8vPzs3Xr1vUYX7hwYXbBBRf0eUx1dXW2cOHCHmPr1q3LCgoKsn379vV5zLJly7KIsNlsNpvNNgK2d955J5fc+FwFkYP29vY4cOBAlJWV9RgvKyuLtra2Po9pa2vrc//9+/dHe3t7lJeX9zpmyZIlUVdX1337o48+ismTJ0dLS8vAFRv9cqienf0aftbi6GEtji7W4+hx6IrJCSecMGD3mVO4HJKXl9fjdpZlvcb+1/59jR9SVFQURUVFvcZLS0v9S3iUKCkpsRZHCWtx9LAWRxfrcfQYM2bgPsSc0z2NHz8+8vPze51d2b17d6+zKoecfPLJfe5fUFAQ48aNy3G6AMBollO4FBYWRkVFRTQ2NvYYb2xsjKqqqj6PmT17dq/9169fH5WVlTF27NgcpwsAjGY5n7upq6uLxx9/PFavXh3btm2LxYsXR0tLS9TW1kbEZ+9PWbBgQff+tbW18e6770ZdXV1s27YtVq9eHatWrYrbbrvtiB+zqKgoli1b1uflI4aWtTh6WIujh7U4uliPo8dgrEXOH4eO+OwL6O67775obW2N6dOnxy9+8Yu44IILIiLi+uuvj3/84x/xxz/+sXv/DRs2xOLFi+Ott96KCRMmxB133NEdOgAAR6pf4QIAMBz8VhEAkAzhAgAkQ7gAAMkQLgBAMo6acFmxYkVMmTIliouLo6KiIpqamj53/w0bNkRFRUUUFxfH1KlT49FHHx2imY58uazFunXr4tJLL40TTzwxSkpKYvbs2fH73/9+CGc7suX6d3HIa6+9FgUFBXH++ecP7gRHkVzXoqurK5YuXRqTJ0+OoqKiOP3002P16tVDNNuRLde1WLNmTZx33nlx7LHHRnl5edxwww2xZ8+eIZrtyPXKK6/ElVdeGRMmTIi8vLx48cUX/+cxA/LaPWC/evQF/OY3v8nGjh2bPfbYY9nWrVuzW2+9NTvuuOOyd999t8/9t2/fnh177LHZrbfemm3dujV77LHHsrFjx2bPPffcEM985Ml1LW699dbs3nvvzf7yl79kb7/9drZkyZJs7Nix2d/+9rchnvnIk+taHPLRRx9lU6dOzWpqarLzzjtvaCY7wvVnLa666qps1qxZWWNjY7Zjx47sz3/+c/baa68N4axHplzXoqmpKRszZkz24IMPZtu3b8+ampqyc845J5s3b94Qz3zkaWhoyJYuXZo9//zzWURkL7zwwufuP1Cv3UdFuMycOTOrra3tMXbWWWdld955Z5/7//jHP87OOuusHmM333xz9vWvf33Q5jha5LoWfTn77LOz5cuXD/TURp3+rsX8+fOzn/70p9myZcuEywDJdS1+97vfZaWlpdmePXuGYnqjSq5r8fOf/zybOnVqj7GHHnoomzhx4qDNcTQ6knAZqNfuYb9UtG/fvti8eXPU1NT0GK+pqYmNGzf2eczrr7/ea//LLrssNm3aFP/+978Hba4jXX/W4r8dPHgw9u7dO6C/BDoa9XctnnjiiXjnnXdi2bJlgz3FUaM/a/HSSy9FZWVl3HfffXHKKafEmWeeGbfddlv885//HIopj1j9WYuqqqrYtWtXNDQ0RJZl8cEHH8Rzzz0XV1xxxVBMmf8wUK/d/fp16IHU3t4eBw4c6PUjjWVlZb1+nPGQtra2Pvffv39/tLe3R3l5+aDNdyTrz1r8t/vvvz8++eSTuPrqqwdjiqNGf9bi73//e9x5553R1NQUBQXD/qc9YvRnLbZv3x6vvvpqFBcXxwsvvBDt7e3x/e9/Pz788EPvc/kC+rMWVVVVsWbNmpg/f37861//iv3798dVV10Vv/zlL4diyvyHgXrtHvYzLofk5eX1uJ1lWa+x/7V/X+PkLte1OOSZZ56Jn/3sZ7F27do46aSTBmt6o8qRrsWBAwfimmuuieXLl8eZZ545VNMbVXL5uzh48GDk5eXFmjVrYubMmXH55ZfHAw88EE8++aSzLgMgl7XYunVrLFy4MO66667YvHlzvPzyy7Fjxw4/OzNMBuK1e9j/t2z8+PGRn5/fq5Z3797dq8wOOfnkk/vcv6CgIMaNGzdocx3p+rMWh6xduzZuvPHGePbZZ+OSSy4ZzGmOCrmuxd69e2PTpk3R3Nwct9xyS0R89uKZZVkUFBTE+vXr4+KLLx6SuY80/fm7KC8vj1NOOSVKS0u7x6ZNmxZZlsWuXbvijDPOGNQ5j1T9WYv6+vqYM2dO3H777RERce6558Zxxx0X1dXVcc899zhDP4QG6rV72M+4FBYWRkVFRTQ2NvYYb2xsjKqqqj6PmT17dq/9169fH5WVlTF27NhBm+tI15+1iPjsTMv1118fTz/9tOvGAyTXtSgpKYk333wztmzZ0r3V1tbGV7/61diyZUvMmjVrqKY+4vTn72LOnDnx/vvvx8cff9w99vbbb8eYMWNi4sSJgzrfkaw/a/Hpp5/GmDE9X+ry8/Mj4v//3z5DY8Beu3N6K+8gOfTxtlWrVmVbt27NFi1alB133HHZP/7xjyzLsuzOO+/Mrr322u79D32kavHixdnWrVuzVatW+Tj0AMl1LZ5++umsoKAge+SRR7LW1tbu7aOPPhqupzBi5LoW/82nigZOrmuxd+/ebOLEidm3v/3t7K233so2bNiQnXHGGdlNN900XE9hxMh1LZ544omsoKAgW7FiRfbOO+9kr776alZZWZnNnDlzuJ7CiLF3796subk5a25uziIie+CBB7Lm5ubuj6YP1mv3UREuWZZljzzySDZ58uSssLAwmzFjRrZhw4buf3bddddlF154YY/9//jHP2Zf+9rXssLCwuy0007LVq5cOcQzHrlyWYsLL7wwi4he23XXXTf0Ex+Bcv27+E/CZWDluhbbtm3LLrnkkuyYY47JJk6cmNXV1WWffvrpEM96ZMp1LR566KHs7LPPzo455pisvLw8++53v5vt2rVriGc98vzhD3/43P/+D9Zrd16WOVcGAKRh2N/jAgBwpIQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAk4/8BrQWhjBP+6s8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot train and test loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(1, epochs+1)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "#ensor.detach().numpy()\n",
    "print(train_loss_values[0].value())\n",
    "train_losses = []\n",
    "ax.plot(x, train_loss_values.numpy(), label=\"train loss\")\n",
    "#ax.plot(x, test_loss_values.detach().numpy(), label=\"test loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Cross Entropy Loss\")\n",
    "ax.set_title(\"Train and test loss over 20 epochs for BERT E2E\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d899e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ae64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d22acdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/#\n",
    "f = open(\"Federalist Papers/all.txt\", \"r\")\n",
    "wholetext = []\n",
    "wholetext.append(f.read())\n",
    "f.close()\n",
    "#analyzer=text_processing\n",
    "#bow_transformer = CountVectorizer().fit(text_processing(wholetext))\n",
    "bow_transformer = CountVectorizer().fit(wholetext)\n",
    "# bow_transformer = CountVectorizer(analyzer=text_processing).fit(train_df.text.values)\n",
    "# text_bow_train = bow_transformer.transform(train_df.text.values)\n",
    "# text_bow_test = bow_transformer.transform(test_df.text.values)\n",
    "\n",
    "#textprepath = \"Federalist Papers/fed paper \"\n",
    "#wholetext = \"\"\n",
    "#trains = np.zeros((85,bow_transformer.transform(['']).toarray().shape[1]))#[0] * 85\n",
    "#texts = []\n",
    "#for i in range(85):\n",
    "    #f = open(f\"{textprepath}{i + 1}.txt\", \"r\")\n",
    "    #text = f.read()\n",
    "    #parts = text.split(\"\\n\", 1) #split out the first line\n",
    "    #f.close()\n",
    "    #parts = text_processing(parts[1])\n",
    "    #print(parts)\n",
    "    #wholetext += parts[0] + \"\\n\"\n",
    "    #print(i)\n",
    "#bow_transformer = CountVectorizer().fit(text_processing(wholetext))\n",
    "#trains = bow_transformer.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3b51f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textprepath = \"Federalist Papers/fed paper \"\n",
    "#trains = np.zeros((85,bow_transformer.transform(['']).toarray().shape[1]))#[0] * 85\n",
    "texts = []\n",
    "for i in range(85):\n",
    "    f = open(f\"{textprepath}{i + 1}.txt\", \"r\")\n",
    "    text = f.read()\n",
    "    parts = text.split(\"\\n\", 1) #split out the first line\n",
    "    f.close()\n",
    "    parts = text_processing(parts[1])\n",
    "    texts.append(parts)#[1])\n",
    "    print(i)\n",
    "trains = bow_transformer.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8c71f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trains.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17e2c825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 22)\t-1\n",
      "  (0, 132)\t-1\n",
      "  (0, 135)\t1\n",
      "  (0, 169)\t1\n",
      "  (0, 190)\t1\n",
      "  (0, 194)\t-1\n",
      "  (0, 209)\t1\n",
      "  (0, 218)\t-1\n",
      "  (0, 222)\t-1\n",
      "  (0, 235)\t1\n",
      "  (0, 247)\t-1\n",
      "  (0, 250)\t-1\n",
      "  (0, 256)\t1\n",
      "  (0, 268)\t1\n",
      "  (0, 275)\t1\n",
      "  (0, 280)\t1\n",
      "  (0, 281)\t1\n",
      "  (0, 328)\t-1\n",
      "  (0, 331)\t2\n",
      "  (0, 344)\t1\n",
      "  (0, 349)\t1\n",
      "  (0, 357)\t-3\n",
      "  (0, 358)\t-1\n",
      "  (0, 359)\t-2\n",
      "  (0, 363)\t1\n",
      "  :\t:\n",
      "  (0, 8825)\t1\n",
      "  (0, 8827)\t-2\n",
      "  (0, 8829)\t-1\n",
      "  (0, 8830)\t-1\n",
      "  (0, 8835)\t-1\n",
      "  (0, 8842)\t23\n",
      "  (0, 8849)\t-2\n",
      "  (0, 8850)\t-2\n",
      "  (0, 8851)\t-1\n",
      "  (0, 8853)\t-1\n",
      "  (0, 8854)\t-1\n",
      "  (0, 8857)\t-1\n",
      "  (0, 8859)\t-7\n",
      "  (0, 8865)\t-2\n",
      "  (0, 8876)\t-1\n",
      "  (0, 8880)\t-1\n",
      "  (0, 8889)\t-2\n",
      "  (0, 8890)\t-3\n",
      "  (0, 8904)\t2\n",
      "  (0, 8906)\t-1\n",
      "  (0, 8916)\t1\n",
      "  (0, 8917)\t-2\n",
      "  (0, 8923)\t7\n",
      "  (0, 8925)\t10\n",
      "  (0, 8928)\t3\n"
     ]
    }
   ],
   "source": [
    "print(trains[0]-trains[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837357c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = make_pipeline(StandardScaler(), SVC())#= svm.SVC()\n",
    "std = StandardScaler(with_mean=False)\n",
    "clf = SVC()\n",
    "std.fit(bow_transformer.transform(wholetext))#, with_mean=False)\n",
    "scaled = std.transform(trains[known])\n",
    "clf.fit(scaled, codes[known])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21255f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 2 2 1 1 1 1 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 1 1 1 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(codes[known])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a826e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(clf.predict((trains[17])))\n",
    "#print(clf.predict(trains[63]))\n",
    "#print(clf.predict(trains[50]))\n",
    "for i in range(85):\n",
    "    print(clf.predict(std.transform(trains[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer() #make object of Count Vectorizer\n",
    "corpus = [\n",
    "      'This is a cat.',\n",
    "      'It likes to roam in the garden',\n",
    "      'It is black in color',\n",
    "      'The cat does not like the dog.',\n",
    "      ]\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "#print(X)\n",
    "#print(X) to see count given to words\n",
    "\n",
    "#vectorizer.get_feature_names() == (\n",
    "#['cat', 'color', 'roam', 'The', 'garden',\n",
    "# 'dog', 'black', 'like', 'does', 'not',\n",
    "# 'the', 'in', 'likes'])\n",
    "\n",
    "#X.toarray()\n",
    "#used to convert X into numpy array\n",
    "\n",
    "#a = vectorizer.transform(['A new cat.', 'The cat does not like']).toarray()\n",
    "a = vectorizer.transform(['']).toarray().shape[1]\n",
    "# Checking it for a new document\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4554b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 53113\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text into a list of tokens\n",
    "    \"\"\"\n",
    "    return [tok.text.lower() for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text into a list of tokens\n",
    "    \"\"\"\n",
    "    return [tok.text.lower() for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab.vocab_factory import build_vocab_from_iterator\n",
    "def yield_de_tokens(data_iter):\n",
    "    for pair in data_iter:\n",
    "        yield tokenize_de(pair[0])\n",
    "\n",
    "\n",
    "def yield_eng_tokens(data_iter):\n",
    "    for pair in data_iter:\n",
    "        yield tokenize_en(pair[1])\n",
    "        \n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "de_vocab = build_vocab_from_iterator(\n",
    "    yield_de_tokens(train_data), min_freq=2,\n",
    "    specials=special_symbols, special_first=True)\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    yield_eng_tokens(train_data), min_freq=2,\n",
    "    specials=special_symbols, special_first=True)\n",
    "\n",
    "en_vocab.set_default_index(UNK_IDX)\n",
    "de_vocab.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c481b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_transform(x):\n",
    "    '''\n",
    "    Return a list of indices corresponding to tokenized German text.\n",
    "    '''\n",
    "    return ([de_vocab['<bos>']] +\n",
    "            [de_vocab[token] for token in tokenize_de(x)] +\n",
    "            [de_vocab['<eos>']])\n",
    "\n",
    "def en_transform(x):\n",
    "    '''\n",
    "    Return a list of indices corresponding to tokenized Englist text.\n",
    "    '''\n",
    "    return ([en_vocab['<bos>']] +\n",
    "            [en_vocab[token] for token in tokenize_en(x)] +\n",
    "            [en_vocab['<eos>']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e529968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    '''\n",
    "    Collect samples from the data loader into a batch.\n",
    "    Returns a tensor of shape {max length} x {batch size}\n",
    "    '''\n",
    "    de_lst, en_lst = [], []\n",
    "    ge_max_len = 0\n",
    "    en_max_len = 0\n",
    "\n",
    "    for de, en in batch:\n",
    "        de_lst.append(torch.LongTensor(de_transform(de)))\n",
    "        en_lst.append(torch.LongTensor(en_transform(en)))\n",
    "\n",
    "    de_batch = pad_sequence(de_lst, batch_first=False,\n",
    "                            padding_value=PAD_IDX)\n",
    "    en_batch = pad_sequence(en_lst, batch_first=False,\n",
    "                            padding_value=PAD_IDX)\n",
    "    return de_batch, en_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6389569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, source_vocab_size, emb_dim, hid_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.embed = nn.Embedding(source_vocab_size, emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.gru = nn.GRU(input_size = emb_dim, hidden_size = hid_dim)#, batch_first = True)\n",
    "        ### WRITE YOUR CODE BELOW ### self.hid_dim = hid_dim\n",
    "\n",
    "    def forward(self, src):\n",
    "        a = self.embed(src)\n",
    "        b = self.dropout(a)\n",
    "        output, houtput = self.gru(b)#, hidden_input)\n",
    "        return houtput "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"*This is the Project Gutenberg Etext of The Federalist Papers.*\n",
    "*****This file should be named feder16.txt or feder16.zip******\n",
    "The release date of this Project Gutenberg Etext:  June 6, 1992\n",
    "[Date last updated: July 10, 2004]\n",
    "\n",
    "Corrected EDITIONS of our etexts get a new NUMBER, feder17.txt.\n",
    "VERSIONS based on separate sources get new LETTER, feder10a.txt.\n",
    "\n",
    "\n",
    "DISCLAIMER\"\"\"\n",
    "print(text_processing(test))\n",
    "print(\"text_processing(wholetext)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
